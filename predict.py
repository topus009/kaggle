#!/usr/bin/env python3
"""
CAPTCHA OCR Prediction Script
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –Ω–∞ CAPTCHA –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
"""

import os
import sys
import numpy as np
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
from PIL import Image
import argparse
import glob

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏
IMG_WIDTH = 200
IMG_HEIGHT = 60
MAX_SEQUENCE_LENGTH = 7

def load_model(model_path="output/model.keras"):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
    try:
        print(f"–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑ {model_path}...")
        model = keras.models.load_model(model_path)
        print("‚úì –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        return model
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        return None

def load_char_mappings():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ª–æ–≤–∞—Ä–∏ —Å–∏–º–≤–æ–ª–æ–≤"""
    # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä–∏ —Å–∏–º–≤–æ–ª–æ–≤ (–¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å –æ–±—É—á–µ–Ω–∏–µ–º)
    characters = sorted(set('–∞–±–≤–≥–¥–µ–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è0123456789'))
    char_to_num = {v: i for i, v in enumerate(characters)}
    num_to_char = {str(i): v for i, v in enumerate(characters)}
    num_to_char['-1'] = 'UKN'  # –î–ª—è CTC –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
    
    print(f"–ê–ª—Ñ–∞–≤–∏—Ç ({len(characters)} —Å–∏–º–≤–æ–ª–æ–≤): {characters}")
    return char_to_num, num_to_char

def preprocess_image(image_path, img_width=IMG_WIDTH, img_height=IMG_HEIGHT):
    """–ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –º–æ–¥–µ–ª–∏"""
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        img = tf.io.read_file(image_path)
        
        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º (–ø—Ä–æ–±—É–µ–º PNG, –∑–∞—Ç–µ–º JPEG)
        try:
            img = tf.io.decode_png(img, channels=3)
        except:
            img = tf.io.decode_jpeg(img, channels=3)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ float32 –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        img = tf.image.convert_image_dtype(img, tf.float32)
        
        # –¢—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä—É–µ–º (width, height, channels)
        img = tf.transpose(img, perm=[1, 0, 2])
        
        # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        img = tf.image.resize(img, [img_width, img_height])
        
        # –î–æ–±–∞–≤–ª—è–µ–º batch dimension
        img = tf.expand_dims(img, 0)
        
        return img.numpy()
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {image_path}: {e}")
        return None

def decode_predictions(predictions, num_to_char):
    """–î–µ–∫–æ–¥–∏—Ä—É–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –≤ —Ç–µ–∫—Å—Ç"""
    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é
    input_len = np.ones(predictions.shape[0]) * predictions.shape[1]
    results = tf.keras.backend.ctc_decode(predictions, input_length=input_len, greedy=True)[0][0]
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ç–µ–∫—Å—Ç
    texts = []
    for result in results:
        text = ""
        for idx in result:
            if idx != -1:  # -1 –æ–∑–Ω–∞—á–∞–µ—Ç padding
                char = num_to_char.get(str(idx.numpy()), '')
                if char != 'UKN':
                    text += char
        texts.append(text)
    
    return texts

def predict_single_image(model, image_path, char_to_num, num_to_char):
    """–ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    print(f"\nüîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º: {os.path.basename(image_path)}")
    
    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    processed_img = preprocess_image(image_path)
    if processed_img is None:
        return None
    
    # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    try:
        predictions = model.predict(processed_img, verbose=0)
        predicted_text = decode_predictions(predictions, num_to_char)[0]
        
        print(f"üìù –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: '{predicted_text}'")
        return predicted_text
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
        return None

def visualize_prediction(image_path, predicted_text, save_path=None):
    """–í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º"""
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        img = Image.open(image_path)
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–∏–≥—É—Ä—É
        plt.figure(figsize=(10, 4))
        plt.imshow(img, cmap='gray')
        plt.title(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: '{predicted_text}'", fontsize=16, fontweight='bold')
        plt.axis('off')
        
        if save_path:
            plt.savefig(save_path, bbox_inches='tight', dpi=150)
            print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {save_path}")
        
        plt.show()
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")

def main():
    parser = argparse.ArgumentParser(description='CAPTCHA OCR Prediction')
    parser.add_argument('--image', '-i', type=str, help='–ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é')
    parser.add_argument('--folder', '-f', type=str, help='–ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏')
    parser.add_argument('--model', '-m', type=str, default='output/model.keras', help='–ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏')
    parser.add_argument('--output', '-o', type=str, help='–ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤')
    parser.add_argument('--show', action='store_true', help='–ü–æ–∫–∞–∑–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è')
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("üîÆ CAPTCHA OCR Prediction Script")
    print("=" * 60)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model = load_model(args.model)
    if model is None:
        return
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ª–æ–≤–∞—Ä–∏ —Å–∏–º–≤–æ–ª–æ–≤
    char_to_num, num_to_char = load_char_mappings()
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if args.output:
        os.makedirs(args.output, exist_ok=True)
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    if args.image:
        # –û–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        if not os.path.exists(args.image):
            print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.image}")
            return
        
        predicted_text = predict_single_image(model, args.image, char_to_num, num_to_char)
        
        if predicted_text and args.show:
            visualize_prediction(args.image, predicted_text)
        
        if predicted_text and args.output:
            output_path = os.path.join(args.output, f"result_{os.path.basename(args.image)}")
            visualize_prediction(args.image, predicted_text, output_path)
    
    elif args.folder:
        # –ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
        if not os.path.exists(args.folder):
            print(f"‚ùå –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {args.folder}")
            return
        
        # –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image_extensions = ['*.png', '*.jpg', '*.jpeg', '*.bmp', '*.tiff']
        image_files = []
        for ext in image_extensions:
            image_files.extend(glob.glob(os.path.join(args.folder, ext)))
            image_files.extend(glob.glob(os.path.join(args.folder, ext.upper())))
        
        if not image_files:
            print(f"‚ùå –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –ø–∞–ø–∫–µ: {args.folder}")
            return
        
        print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ {len(image_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        results = []
        for i, image_path in enumerate(image_files):
            predicted_text = predict_single_image(model, image_path, char_to_num, num_to_char)
            if predicted_text:
                results.append((os.path.basename(image_path), predicted_text))
                
                if args.show:
                    visualize_prediction(image_path, predicted_text)
                
                if args.output:
                    output_path = os.path.join(args.output, f"result_{os.path.basename(image_path)}")
                    visualize_prediction(image_path, predicted_text, output_path)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª
        if args.output and results:
            results_file = os.path.join(args.output, "predictions.txt")
            with open(results_file, 'w', encoding='utf-8') as f:
                f.write("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π:\n")
                f.write("=" * 40 + "\n")
                for filename, prediction in results:
                    f.write(f"{filename}: {prediction}\n")
            print(f"üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {results_file}")
    
    else:
        print("‚ùå –£–∫–∞–∂–∏—Ç–µ --image –∏–ª–∏ --folder")
        parser.print_help()

if __name__ == "__main__":
    main()